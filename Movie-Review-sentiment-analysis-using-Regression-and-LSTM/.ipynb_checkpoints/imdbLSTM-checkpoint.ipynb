{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Sentiment Analysis using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from keras.layers import Dense, LSTM,Embedding, SpatialDropout1D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('IMDB-Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns of the dataset\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 elements from the top\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def clean_html(text):\n",
    "    clean=re.compile('<.*?>')\n",
    "    cleantext=re.sub(clean,'',text)\n",
    "    return cleantext\n",
    "    \n",
    "def clean_text1(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub('\\[.*?\\]','',text)\n",
    "    text=re.sub('[%s]'%re.escape(string.punctuation),'',text)\n",
    "    text=re.sub('\\w*\\d\\w*','',text)\n",
    "    return text\n",
    "\n",
    "def clean_text2(text):\n",
    "    text=re.sub('[''\"\",,,]','',text)\n",
    "    text=re.sub('\\n','',text)\n",
    "    return text\n",
    "    \n",
    "cleaned_html=lambda x:clean_html(x)\n",
    "cleaned1=lambda x:clean_text1(x)\n",
    "cleaned2=lambda x:clean_text2(x)\n",
    "\n",
    "data['review']=pd.DataFrame(data.review.apply(cleaned_html))\n",
    "data['review']=pd.DataFrame(data.review.apply(cleaned1))\n",
    "data['review']=pd.DataFrame(data.review.apply(cleaned2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features=5000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(data['review'].values)\n",
    "X = tokenizer.texts_to_sequences(data['review'].values)\n",
    "X = pad_sequences(X,maxlen=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...  121 3931  498]\n",
      " [   0    0    0 ... 1869   72  222]\n",
      " [   0    0    0 ...   63   14  328]\n",
      " ...\n",
      " [   0    0    0 ... 1626    2    2]\n",
      " [   0    0    0 ...   67  702   41]\n",
      " [   0    0    0 ...  832   10   16]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 600, 64)           320000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 600, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 353,154\n",
      "Trainable params: 353,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 64\n",
    "lstm_out = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=pd.get_dummies(data['sentiment']).values\n",
    "X_train, X_test, Y_train, Y_test = tts(X,Y, test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n",
      "625/625 [==============================] - 901s 1s/step - loss: 0.4308 - accuracy: 0.8015 - val_loss: 0.2960 - val_accuracy: 0.8776\n",
      "Epoch 2/48\n",
      "625/625 [==============================] - 954s 2s/step - loss: 0.2922 - accuracy: 0.8828 - val_loss: 0.2771 - val_accuracy: 0.8913\n",
      "Epoch 3/48\n",
      "625/625 [==============================] - 960s 2s/step - loss: 0.2586 - accuracy: 0.8982 - val_loss: 0.2759 - val_accuracy: 0.8888\n",
      "Epoch 4/48\n",
      "625/625 [==============================] - 960s 2s/step - loss: 0.2399 - accuracy: 0.9049 - val_loss: 0.2882 - val_accuracy: 0.8782\n",
      "Epoch 5/48\n",
      "625/625 [==============================] - 961s 2s/step - loss: 0.2451 - accuracy: 0.9039 - val_loss: 0.3085 - val_accuracy: 0.8776\n",
      "Epoch 6/48\n",
      "625/625 [==============================] - 963s 2s/step - loss: 0.2170 - accuracy: 0.9146 - val_loss: 0.2886 - val_accuracy: 0.8862\n",
      "Epoch 7/48\n",
      "625/625 [==============================] - 987s 2s/step - loss: 0.1993 - accuracy: 0.9228 - val_loss: 0.3088 - val_accuracy: 0.8895\n",
      "Epoch 8/48\n",
      "625/625 [==============================] - 971s 2s/step - loss: 0.1846 - accuracy: 0.9286 - val_loss: 0.3387 - val_accuracy: 0.8848\n",
      "Epoch 9/48\n",
      "625/625 [==============================] - 957s 2s/step - loss: 0.1732 - accuracy: 0.9343 - val_loss: 0.2942 - val_accuracy: 0.8890\n",
      "Epoch 10/48\n",
      "625/625 [==============================] - 960s 2s/step - loss: 0.1679 - accuracy: 0.9349 - val_loss: 0.2947 - val_accuracy: 0.8927\n",
      "Epoch 11/48\n",
      "625/625 [==============================] - 966s 2s/step - loss: 0.1565 - accuracy: 0.9407 - val_loss: 0.3271 - val_accuracy: 0.8897\n",
      "Epoch 12/48\n",
      "625/625 [==============================] - 972s 2s/step - loss: 0.1485 - accuracy: 0.9439 - val_loss: 0.3261 - val_accuracy: 0.8928\n",
      "Epoch 13/48\n",
      "625/625 [==============================] - 973s 2s/step - loss: 0.1430 - accuracy: 0.9471 - val_loss: 0.3435 - val_accuracy: 0.8748\n",
      "Epoch 14/48\n",
      "625/625 [==============================] - 970s 2s/step - loss: 0.1415 - accuracy: 0.9474 - val_loss: 0.3430 - val_accuracy: 0.8934\n",
      "Epoch 15/48\n",
      "625/625 [==============================] - 974s 2s/step - loss: 0.1305 - accuracy: 0.9507 - val_loss: 0.3433 - val_accuracy: 0.8824\n",
      "Epoch 16/48\n",
      "625/625 [==============================] - 967s 2s/step - loss: 0.1243 - accuracy: 0.9535 - val_loss: 0.3369 - val_accuracy: 0.8893\n",
      "Epoch 17/48\n",
      "625/625 [==============================] - 965s 2s/step - loss: 0.1218 - accuracy: 0.9531 - val_loss: 0.3696 - val_accuracy: 0.8834\n",
      "Epoch 18/48\n",
      "625/625 [==============================] - 969s 2s/step - loss: 0.1098 - accuracy: 0.9601 - val_loss: 0.3537 - val_accuracy: 0.8870\n",
      "Epoch 19/48\n",
      "625/625 [==============================] - 967s 2s/step - loss: 0.1180 - accuracy: 0.9562 - val_loss: 0.3748 - val_accuracy: 0.8883\n",
      "Epoch 20/48\n",
      "625/625 [==============================] - 969s 2s/step - loss: 0.1122 - accuracy: 0.9588 - val_loss: 0.3461 - val_accuracy: 0.8881\n",
      "Epoch 21/48\n",
      "625/625 [==============================] - 967s 2s/step - loss: 0.1060 - accuracy: 0.9611 - val_loss: 0.3924 - val_accuracy: 0.8874\n",
      "Epoch 22/48\n",
      "625/625 [==============================] - 972s 2s/step - loss: 0.1044 - accuracy: 0.9617 - val_loss: 0.3781 - val_accuracy: 0.8921\n",
      "Epoch 23/48\n",
      "625/625 [==============================] - 965s 2s/step - loss: 0.0918 - accuracy: 0.9661 - val_loss: 0.3855 - val_accuracy: 0.8869\n",
      "Epoch 24/48\n",
      "625/625 [==============================] - 973s 2s/step - loss: 0.0865 - accuracy: 0.9693 - val_loss: 0.3954 - val_accuracy: 0.8893\n",
      "Epoch 25/48\n",
      "625/625 [==============================] - 971s 2s/step - loss: 0.0895 - accuracy: 0.9683 - val_loss: 0.3944 - val_accuracy: 0.8884\n",
      "Epoch 26/48\n",
      "625/625 [==============================] - 970s 2s/step - loss: 0.0942 - accuracy: 0.9671 - val_loss: 0.4264 - val_accuracy: 0.8887\n",
      "Epoch 27/48\n",
      "625/625 [==============================] - 974s 2s/step - loss: 0.0828 - accuracy: 0.9704 - val_loss: 0.4146 - val_accuracy: 0.8891\n",
      "Epoch 28/48\n",
      "625/625 [==============================] - 973s 2s/step - loss: 0.0759 - accuracy: 0.9725 - val_loss: 0.4463 - val_accuracy: 0.8886\n",
      "Epoch 29/48\n",
      "625/625 [==============================] - 966s 2s/step - loss: 0.0799 - accuracy: 0.9718 - val_loss: 0.4450 - val_accuracy: 0.8853\n",
      "Epoch 30/48\n",
      "625/625 [==============================] - 967s 2s/step - loss: 0.0802 - accuracy: 0.9711 - val_loss: 0.4510 - val_accuracy: 0.8849\n",
      "Epoch 31/48\n",
      "625/625 [==============================] - 966s 2s/step - loss: 0.0730 - accuracy: 0.9742 - val_loss: 0.4543 - val_accuracy: 0.8833\n",
      "Epoch 32/48\n",
      "625/625 [==============================] - 966s 2s/step - loss: 0.0668 - accuracy: 0.9768 - val_loss: 0.4696 - val_accuracy: 0.8897\n",
      "Epoch 33/48\n",
      "625/625 [==============================] - 966s 2s/step - loss: 0.0663 - accuracy: 0.9780 - val_loss: 0.4660 - val_accuracy: 0.8882\n",
      "Epoch 34/48\n",
      "625/625 [==============================] - 966s 2s/step - loss: 0.0640 - accuracy: 0.9782 - val_loss: 0.4776 - val_accuracy: 0.8886\n",
      "Epoch 35/48\n",
      "625/625 [==============================] - 970s 2s/step - loss: 0.0624 - accuracy: 0.9789 - val_loss: 0.4704 - val_accuracy: 0.8813\n",
      "Epoch 36/48\n",
      "625/625 [==============================] - 971s 2s/step - loss: 0.0619 - accuracy: 0.9786 - val_loss: 0.4740 - val_accuracy: 0.8859\n",
      "Epoch 37/48\n",
      "625/625 [==============================] - 958s 2s/step - loss: 0.0590 - accuracy: 0.9790 - val_loss: 0.4906 - val_accuracy: 0.8878\n",
      "Epoch 38/48\n",
      "625/625 [==============================] - 878s 1s/step - loss: 0.0572 - accuracy: 0.9808 - val_loss: 0.4639 - val_accuracy: 0.8826\n",
      "Epoch 39/48\n",
      "625/625 [==============================] - 935s 1s/step - loss: 0.0623 - accuracy: 0.9789 - val_loss: 0.4673 - val_accuracy: 0.8855\n",
      "Epoch 40/48\n",
      "625/625 [==============================] - 863s 1s/step - loss: 0.0532 - accuracy: 0.9820 - val_loss: 0.4927 - val_accuracy: 0.8868\n",
      "Epoch 41/48\n",
      "625/625 [==============================] - 868s 1s/step - loss: 0.0565 - accuracy: 0.9806 - val_loss: 0.5008 - val_accuracy: 0.8883\n",
      "Epoch 42/48\n",
      "625/625 [==============================] - 865s 1s/step - loss: 0.0540 - accuracy: 0.9821 - val_loss: 0.4856 - val_accuracy: 0.8550\n",
      "Epoch 43/48\n",
      "625/625 [==============================] - 864s 1s/step - loss: 0.0531 - accuracy: 0.9810 - val_loss: 0.5359 - val_accuracy: 0.8872\n",
      "Epoch 44/48\n",
      "625/625 [==============================] - 866s 1s/step - loss: 0.0505 - accuracy: 0.9826 - val_loss: 0.5027 - val_accuracy: 0.8892\n",
      "Epoch 45/48\n",
      "625/625 [==============================] - 867s 1s/step - loss: 0.0439 - accuracy: 0.9857 - val_loss: 0.5122 - val_accuracy: 0.8849\n",
      "Epoch 46/48\n",
      "625/625 [==============================] - 867s 1s/step - loss: 0.0458 - accuracy: 0.9846 - val_loss: 0.5657 - val_accuracy: 0.8881\n",
      "Epoch 47/48\n",
      "625/625 [==============================] - 944s 2s/step - loss: 0.0444 - accuracy: 0.9844 - val_loss: 0.5315 - val_accuracy: 0.8843\n",
      "Epoch 48/48\n",
      "625/625 [==============================] - 871s 1s/step - loss: 0.0442 - accuracy: 0.9846 - val_loss: 0.5757 - val_accuracy: 0.8817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2520d689460>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "history = model.fit(X_train, Y_train, epochs = 4, batch_size=batch_size,validation_data=(X_test,Y_test),verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
