{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Movie Reviews using LSTM and Keras\n",
    "<hr>\n",
    "<i>Importing libraries</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    # to load dataset\n",
    "import numpy as np     # for mathematic equation\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import stopwords   # to get collection of stopwords\n",
    "from sklearn.model_selection import train_test_split       # for splitting dataset\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
    "from tensorflow.keras.models import Sequential     # the model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense # layers of the architecture\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
    "from tensorflow.keras.models import load_model   # load saved model\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<i>Preview dataset</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review sentiment\n",
      "0      One of the other reviewers has mentioned that ...  positive\n",
      "1      A wonderful little production. <br /><br />The...  positive\n",
      "2      I thought this was a wonderful way to spend ti...  positive\n",
      "3      Basically there's a family where a little boy ...  negative\n",
      "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "...                                                  ...       ...\n",
      "49995  I thought this movie did a down right good job...  positive\n",
      "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
      "49997  I am a Catholic taught in parochial elementary...  negative\n",
      "49998  I'm going to have to disagree with the previou...  negative\n",
      "49999  No one expects the Star Trek movies to be high...  negative\n",
      "\n",
      "[50000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Load and Clean Dataset & Encode Sentiments\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews\n",
      "0        [one, reviewers, mentioned, watching, oz, epis...\n",
      "1        [a, wonderful, little, production, the, filmin...\n",
      "2        [i, thought, wonderful, way, spend, time, hot,...\n",
      "3        [basically, family, little, boy, jake, thinks,...\n",
      "4        [petter, mattei, love, time, money, visually, ...\n",
      "                               ...                        \n",
      "49995    [i, thought, movie, right, good, job, it, crea...\n",
      "49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n",
      "49997    [i, catholic, taught, parochial, elementary, s...\n",
      "49998    [i, going, disagree, previous, comment, side, ...\n",
      "49999    [no, one, expects, star, trek, movies, high, a...\n",
      "Name: review, Length: 50000, dtype: object \n",
      "\n",
      "Sentiment\n",
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        0\n",
      "4        1\n",
      "        ..\n",
      "49995    1\n",
      "49996    0\n",
      "49997    0\n",
      "49998    0\n",
      "49999    0\n",
      "Name: sentiment, Length: 50000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def load_dataset():\n",
    "    df = pd.read_csv('IMDB Dataset.csv')\n",
    "    x_data = df['review']       # Reviews/Input\n",
    "    y_data = df['sentiment']    # Sentiment/Output\n",
    "\n",
    "    # PRE-PROCESS REVIEW\n",
    "    x_data = x_data.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
    "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
    "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])  # remove stop words\n",
    "    x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n",
    "    \n",
    "    # ENCODE SENTIMENT -> 0 & 1\n",
    "    y_data = y_data.replace('positive', 1)\n",
    "    y_data = y_data.replace('negative', 0)\n",
    "\n",
    "    return x_data, y_data\n",
    "\n",
    "x_data, y_data = load_dataset()\n",
    "\n",
    "print('Reviews')\n",
    "print(x_data, '\\n')\n",
    "print('Sentiment')\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Spliting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "13774    [some, gorehound, friends, recommended, live, ...\n",
      "44581    [one, underrated, comedies, dan, akroyd, hilar...\n",
      "48037    [this, movie, lots, potential, beautiful, wome...\n",
      "37054    [this, movie, heart, felt, piece, cinema, help...\n",
      "21392    [i, thought, film, could, bit, complex, psycho...\n",
      "                               ...                        \n",
      "44643    [i, sure, folks, texas, louisiana, border, mus...\n",
      "17865    [first, let, agree, lorenzo, lamas, could, nev...\n",
      "12833    [i, seen, film, many, years, ago, made, lastin...\n",
      "35697    [i, actually, caught, ad, japan, sinks, japane...\n",
      "47858    [i, remember, seeing, promos, show, appeared, ...\n",
      "Name: review, Length: 40000, dtype: object \n",
      "\n",
      "18577    [considering, film, reputation, truly, worst, ...\n",
      "23874    [a, brash, self, centered, army, cadet, arrive...\n",
      "21878    [wow, i, thought, eskimo, limon, awful, embarr...\n",
      "37398    [this, movie, go, one, funniest, movies, histo...\n",
      "40984    [dr, hackenstein, begins, turn, last, century,...\n",
      "                               ...                        \n",
      "6081     [the, contemporary, chapter, u, s, navy, elite...\n",
      "33921    [welcome, collinwood, lot, things, none, follo...\n",
      "24247    [i, like, think, i, seen, ss, doomtrooper, the...\n",
      "15497    [leland, p, fitzgerald, ryan, gosling, committ...\n",
      "4523     [apart, longest, reign, british, history, year...\n",
      "Name: review, Length: 10000, dtype: object \n",
      "\n",
      "Test Set\n",
      "13774    0\n",
      "44581    1\n",
      "48037    0\n",
      "37054    1\n",
      "21392    1\n",
      "        ..\n",
      "44643    0\n",
      "17865    0\n",
      "12833    1\n",
      "35697    1\n",
      "47858    1\n",
      "Name: sentiment, Length: 40000, dtype: int64 \n",
      "\n",
      "18577    0\n",
      "23874    1\n",
      "21878    0\n",
      "37398    1\n",
      "40984    0\n",
      "        ..\n",
      "6081     0\n",
      "33921    1\n",
      "24247    0\n",
      "15497    1\n",
      "4523     1\n",
      "Name: sentiment, Length: 10000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\n",
    "\n",
    "print('Train Set')\n",
    "print(x_train, '\\n')\n",
    "print(x_test, '\\n')\n",
    "print('Test Set')\n",
    "print(y_train, '\\n')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<i>Function for getting the maximum review length, by calculating the mean of all the reviews length (using <b>numpy.mean</b>)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_length():\n",
    "    review_length = []\n",
    "    for review in x_train:\n",
    "        review_length.append(len(review))\n",
    "\n",
    "    return int(np.ceil(np.mean(review_length)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Tokenize and Pad/Truncate Reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded X Train\n",
      " [[  383 35769   261 ...  6809 10937    73]\n",
      " [    5  2061  1211 ...     0     0     0]\n",
      " [    8     3   631 ...     0     0     0]\n",
      " ...\n",
      " [    1    37     4 ... 39881  2864 11636]\n",
      " [    1    75   916 ...   352  2884  6708]\n",
      " [    1   288   222 ...    44 13242  1070]] \n",
      "\n",
      "Encoded X Test\n",
      " [[  986     4  2459 ...  1389   731  3329]\n",
      " [   40 12087   444 ...  3362   261    41]\n",
      " [ 1220     1   102 ...     0     0     0]\n",
      " ...\n",
      " [    1     6    29 ...     0     0     0]\n",
      " [ 6769  1276  9229 ... 30935  3041  3263]\n",
      " [  889  6007  5951 ...     2   243 18768]] \n",
      "\n",
      "Maximum review length:  130\n"
     ]
    }
   ],
   "source": [
    "# ENCODE REVIEW\n",
    "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
    "token.fit_on_texts(x_train)\n",
    "x_train = token.texts_to_sequences(x_train)\n",
    "x_test = token.texts_to_sequences(x_test)\n",
    "\n",
    "max_length = get_max_length()\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
    "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
    "\n",
    "print('Encoded X Train\\n', x_train, '\\n')\n",
    "print('Encoded X Test\\n', x_test, '\\n')\n",
    "print('Maximum review length: ', max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Build Architecture/Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 130, 32)           2963040   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,987,937\n",
      "Trainable params: 2,987,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ARCHITECTURE\n",
    "EMBED_DIM = 32\n",
    "LSTM_OUT = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
    "model.add(LSTM(LSTM_OUT))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'models/LSTM.h5',\n",
    "    monitor='accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "313/313 [==============================] - 56s 170ms/step - loss: 0.4798 - accuracy: 0.7336\n",
      "\n",
      "Epoch 00001: accuracy improved from -inf to 0.73355, saving model to models\\LSTM.h5\n",
      "Epoch 2/30\n",
      "313/313 [==============================] - 47s 151ms/step - loss: 0.2177 - accuracy: 0.9210\n",
      "\n",
      "Epoch 00002: accuracy improved from 0.73355 to 0.92098, saving model to models\\LSTM.h5\n",
      "Epoch 3/30\n",
      "313/313 [==============================] - 48s 152ms/step - loss: 0.1247 - accuracy: 0.9599\n",
      "\n",
      "Epoch 00003: accuracy improved from 0.92098 to 0.95995, saving model to models\\LSTM.h5\n",
      "Epoch 4/30\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.0740 - accuracy: 0.9787\n",
      "\n",
      "Epoch 00004: accuracy improved from 0.95995 to 0.97870, saving model to models\\LSTM.h5\n",
      "Epoch 5/30\n",
      "313/313 [==============================] - 134s 428ms/step - loss: 0.0539 - accuracy: 0.9854\n",
      "\n",
      "Epoch 00005: accuracy improved from 0.97870 to 0.98540, saving model to models\\LSTM.h5\n",
      "Epoch 6/30\n",
      "313/313 [==============================] - 304s 974ms/step - loss: 0.0436 - accuracy: 0.9888\n",
      "\n",
      "Epoch 00006: accuracy improved from 0.98540 to 0.98880, saving model to models\\LSTM.h5\n",
      "Epoch 7/30\n",
      "313/313 [==============================] - 59s 187ms/step - loss: 0.0437 - accuracy: 0.9884\n",
      "\n",
      "Epoch 00007: accuracy did not improve from 0.98880\n",
      "Epoch 8/30\n",
      "313/313 [==============================] - 50s 159ms/step - loss: 0.0343 - accuracy: 0.9911\n",
      "\n",
      "Epoch 00008: accuracy improved from 0.98880 to 0.99105, saving model to models\\LSTM.h5\n",
      "Epoch 9/30\n",
      "313/313 [==============================] - 48s 152ms/step - loss: 0.0267 - accuracy: 0.9937\n",
      "\n",
      "Epoch 00009: accuracy improved from 0.99105 to 0.99370, saving model to models\\LSTM.h5\n",
      "Epoch 10/30\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.0211 - accuracy: 0.9954\n",
      "\n",
      "Epoch 00010: accuracy improved from 0.99370 to 0.99542, saving model to models\\LSTM.h5\n",
      "Epoch 11/30\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.0990 - accuracy: 0.9764\n",
      "\n",
      "Epoch 00011: accuracy did not improve from 0.99542\n",
      "Epoch 12/30\n",
      "313/313 [==============================] - 48s 155ms/step - loss: 0.0918 - accuracy: 0.9768\n",
      "\n",
      "Epoch 00012: accuracy did not improve from 0.99542\n",
      "Epoch 13/30\n",
      "313/313 [==============================] - 48s 154ms/step - loss: 0.0282 - accuracy: 0.9934\n",
      "\n",
      "Epoch 00013: accuracy did not improve from 0.99542\n",
      "Epoch 14/30\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.0306 - accuracy: 0.9939\n",
      "\n",
      "Epoch 00014: accuracy did not improve from 0.99542\n",
      "Epoch 15/30\n",
      "313/313 [==============================] - 48s 154ms/step - loss: 0.0225 - accuracy: 0.9951\n",
      "\n",
      "Epoch 00015: accuracy did not improve from 0.99542\n",
      "Epoch 16/30\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 0.0152 - accuracy: 0.9972\n",
      "\n",
      "Epoch 00016: accuracy improved from 0.99542 to 0.99722, saving model to models\\LSTM.h5\n",
      "Epoch 17/30\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.0524 - accuracy: 0.9859\n",
      "\n",
      "Epoch 00017: accuracy did not improve from 0.99722\n",
      "Epoch 18/30\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.3467 - accuracy: 0.8665\n",
      "\n",
      "Epoch 00018: accuracy did not improve from 0.99722\n",
      "Epoch 19/30\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.4857 - accuracy: 0.7911\n",
      "\n",
      "Epoch 00019: accuracy did not improve from 0.99722\n",
      "Epoch 20/30\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.3493 - accuracy: 0.8573\n",
      "\n",
      "Epoch 00020: accuracy did not improve from 0.99722\n",
      "Epoch 21/30\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.0496 - accuracy: 0.9870\n",
      "\n",
      "Epoch 00021: accuracy did not improve from 0.99722\n",
      "Epoch 22/30\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 0.0179 - accuracy: 0.9964\n",
      "\n",
      "Epoch 00022: accuracy did not improve from 0.99722\n",
      "Epoch 23/30\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.0098 - accuracy: 0.9986\n",
      "\n",
      "Epoch 00023: accuracy improved from 0.99722 to 0.99857, saving model to models\\LSTM.h5\n",
      "Epoch 24/30\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 0.0083 - accuracy: 0.9989\n",
      "\n",
      "Epoch 00024: accuracy improved from 0.99857 to 0.99890, saving model to models\\LSTM.h5\n",
      "Epoch 25/30\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.0079 - accuracy: 0.9990\n",
      "\n",
      "Epoch 00025: accuracy improved from 0.99890 to 0.99897, saving model to models\\LSTM.h5\n",
      "Epoch 26/30\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 0.0077 - accuracy: 0.9990\n",
      "\n",
      "Epoch 00026: accuracy did not improve from 0.99897\n",
      "Epoch 27/30\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.0247 - accuracy: 0.9949\n",
      "\n",
      "Epoch 00027: accuracy did not improve from 0.99897\n",
      "Epoch 28/30\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 0.0158 - accuracy: 0.9967\n",
      "\n",
      "Epoch 00028: accuracy did not improve from 0.99897\n",
      "Epoch 29/30\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.0129 - accuracy: 0.9975\n",
      "\n",
      "Epoch 00029: accuracy did not improve from 0.99897\n",
      "Epoch 30/30\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.0101 - accuracy: 0.9982\n",
      "\n",
      "Epoch 00030: accuracy did not improve from 0.99897\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size = 128, epochs = 30, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Prediction: 8651\n",
      "Wrong Prediction: 1349\n",
      "Accuracy: 86.50999999999999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "true = 0\n",
    "for i, y in enumerate(y_test):\n",
    "    if y == y_pred[i]:\n",
    "        true += 1\n",
    "\n",
    "print('Correct Prediction: {}'.format(true))\n",
    "print('Wrong Prediction: {}'.format(len(y_pred) - true))\n",
    "print('Accuracy: {}'.format(true/len(y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Load Saved Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('models/LSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Review: this is a really intense movie.\n"
     ]
    }
   ],
   "source": [
    "review = str(input('Movie Review: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned:  this is a really intense movie\n",
      "Filtered:  ['really intense movie']\n"
     ]
    }
   ],
   "source": [
    "# Pre-process input\n",
    "regex = re.compile(r'[^a-zA-Z\\s]')\n",
    "review = regex.sub('', review)\n",
    "print('Cleaned: ', review)\n",
    "\n",
    "words = review.split(' ')\n",
    "filtered = [w for w in words if w not in english_stops]\n",
    "filtered = ' '.join(filtered)\n",
    "filtered = [filtered.lower()]\n",
    "\n",
    "print('Filtered: ', filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  13 1443    3    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "tokenize_words = token.texts_to_sequences(filtered)\n",
    "tokenize_words = pad_sequences(tokenize_words, maxlen=max_length, padding='post', truncating='post')\n",
    "print(tokenize_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9954866]]\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(tokenize_words)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "if result >= 0.7:\n",
    "    print('positive')\n",
    "else:\n",
    "    print('negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
